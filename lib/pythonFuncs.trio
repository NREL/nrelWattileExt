name:wattilePythonEventCleanup
func
nodoc
overridable
src:
  (session, model) => do
    // Temporary: remove event logs to prevent accumulation
    // Eventually, this should be fixed in Wattile itself
    
    // Get local directory uri from model record
    uri: (model.toRec)["uri"]
    
    // Convert absolute to relative Uri; see wattilPythonModelSetup()
    if (uri.toStr.startsWith("/")) uri = uriPath(uri)[2..-1].pathToUri.uriPlusSlash
    
    // List event files
    eventFiles: ioDir(uri)
      .findAll(f => f->name.startsWith("events.out.tfevents."))
      .colToList("name")
    
    // No files to remove?
    if (eventFiles.isEmpty) return "No event files to delete."
    
    // Use Python to remove files
    session
      .pyExec("import os")
      .pyDefine("model_dir", "/" + uri.toStr)
      .pyDefine("event_files", eventFiles)
      .pyExec("event_file_paths = list(map(lambda f: pathlib.Path(model_dir) / f, event_files))")
      .pyExec("""for f in event_file_paths:
                   if os.path.isfile(f):
                     os.remove(f)""")
  
    // Return number of files removed
    session.pyEval("'Deleted ' + str(len(event_file_paths)) + ' event files.'")
  end
---
name:wattilePythonInit
func
overridable
src:
  // Python session initialization callback
  (session) => do
    // Import required Python libraries and functions
    session
      .pyExec("import hxpy")
      .pyExec("import json")
      .pyExec("import pathlib")
      .pyExec("import pandas")
      .pyExec("import numpy")
      .pyExec("import xarray")
      .pyExec("from wattile.models import AlfaModel, BravoModel")
      .pyExec("from wattile.buildings_processing import prep_for_rnn")
      .pyExec("from wattile.entry_point import create_input_dataframe, run_model")
  end
---
name:wattilePythonModelPredict
func
overridable
src:
  (session, model, span) => do
    // Get predictors
    predictors: model->predictors
  
    // Prediction time span start/end
    spanStart: span.toSpan.start
    spanEnd: span.toSpan.end
  
    // Prediction units: from model, fallback to target
    if (model.has("unit")) do
      predUnit: model->unit
    else if (model.has("targetRef")) do
      predUnit: readById(model->targetRef)["unit"]
    else do
      predUnit: null
    end
    
    // Prediction timezone: from model, fallback to target
    if (model.has("tz")) do
      predTz: model->tz
    else if (model.has("targetRef")) do
      predTz: readById(model->targetRef)["tz"]
    else do
      predTz: null
    end
  
    // Load model config
    modelConfig: ioReadJson(model->uri + "configs.json")
  
    // Verify model configuration
    if (modelConfig->learning_algorithm->use_case != "prediction") do
      throw "Model " + model.dis + " is not configured for prediction. Did you run model setup?"
    end
    if (not model->uri.toStr.endsWith(modelConfig->data_output->exp_dir[1..-1])) do
      throw "Model " + model.dis + " directory mismatch. Did you run model setup?"
    end
    
    // Load history read options
    if (model.has("opts")) do
      readOpts: model->opts
    else do
      readOpts: {} // Use defaults
    end
  
    // Get model architecture
    // TO DO: It would be nice to load model objects directly so I don't have
    // to decipher the architecture version here...
    modelArch: modelConfig->learning_algorithm->arch_version
    if (modelArch == "alfa") do
      modelClass: "AlfaModel"
    else if (modelArch == "bravo") do
      modelClass: "BravoModel"
    else do
      throw "Unsupported model architecture version: " + arch
    end
  
    // Load model configuration
    session
      .pyDefine("model_dir", modelConfig->data_output->exp_dir)
      .pyExec("configs_path = pathlib.Path(model_dir) / 'configs.json'")
      .pyExec("""with open(configs_path, 'r', encoding='utf-8') as f:
                     configs = json.load(f)""")
    
    // Instantiate model
    session.pyExec("model = " + modelClass + "(configs)")
  
    // Determine read time span for prediction
    if (spanStart == spanEnd) do
      // Single timestep
      session
        .pyDefine("prediction_time", spanStart)
        .pyExec("prediction_time = pandas.Timestamp(prediction_time)")
        .pyExec("input_start, input_end = model.get_input_window_for_output_time(prediction_time)")
    else do
      // Multiple timesteps
      session
        .pyDefine("first_prediction_time", spanStart)
        .pyDefine("last_prediction_time", spanEnd)
        .pyExec("first_prediction_time = pandas.Timestamp(first_prediction_time)")
        .pyExec("last_prediction_time = pandas.Timestamp(last_prediction_time)")
        .pyExec("input_start = model.get_input_window_for_output_time(first_prediction_time)[0]")
        .pyExec("input_end = model.get_input_window_for_output_time(last_prediction_time)[1]")
    end
    readSpan: session.pyEval("input_start")..session.pyEval("input_end")
  
    // Read and prepare data: see wattileReadHis()
    data: wattileReadHis(predictors, readSpan, readOpts)
      .map() row => row.set("ts", row->ts.toTimeZone("UTC")) // Temporary; will be handled by Wattile in the future
    
    // Adjust model config start/end times (Temporary? Avoids dropping data.)
    session
      .pyExec("configs['data_input']['start_time'] = input_start.isoformat()")
      .pyExec("configs['data_input']['end_time'] = input_end.isoformat()")
    
    // Get column name specification for SkySpark -> Python conversion
    getSkySparkColName: (column) => name(column)
    getPythonColName: (column) => do
      id: column.meta["id"]
      if (id == null) return null // Should only happen for "ts"
      val: predictors.find(p => id==p->id)->column
    end
    columnSpec: data
      .gridColsToDict(getSkySparkColName, getPythonColName)
      .findAll(v => v != null)
  
    // Load data into Python
    session
      .pyDefine("predictor_grid", data)
      .pyExec("predictor_data_frame = predictor_grid.to_dataframe()") // Pandas data frame
      .pyExec("predictor_data_frame = predictor_data_frame.set_index('ts')")
  
    // Rename columns
    session
      .pyDefine("column_specification", columnSpec)
      .pyExec("predictor_data_frame = predictor_data_frame.rename(columns=column_specification)")
      .pyExec("predictor_data_frame[configs['data_input']['target_var']] = -999") // Temporary; prevents dropping rows
  
    // TO DO: Should be able to remove the placeholder target var
  
    // Prep data and run prediction
    session
      .pyExec("train_df, val_df = prep_for_rnn(configs, predictor_data_frame)")
      .pyExec("results = run_model(configs, train_df, val_df)")
  
    // Return tidy results:
    //   1. Convert to Pandas series (with multi-index)
    //   2. Convert to Pandas data frame (still with multi-index)
    //   3. Convert index to data frame columns
    //   4. Add prediction timestamp as nominal timestamp + horizon
    //   5. Convert horizon to numeric in seconds
    results: session
      .pyExec("tidy_results = results.to_series().to_frame(name='pred_val').reset_index()")
      .pyExec("tidy_results['pred_ts'] = tidy_results['timestamp'] + tidy_results['horizon']")
      .pyExec("tidy_results['horizon'] = tidy_results['horizon'].map(lambda h: h.total_seconds())")
      .pyEval("tidy_results")
  
    // Post-processing
    results = results.map() row => do
      // Units for horizon
      row = row.set("horizon", row->horizon.as("s"))
      
      // Units for predicted values
      row = row.set("pred_val", row->pred_val.as(predUnit))
      
      // Handle timezone
      if (predTz != null) do
        row = row
          .set("timestamp", row->timestamp.toTimeZone(predTz))
          .set("pred_ts", row->pred_ts.toTimeZone(predTz))
      end
      
      // Return
      return row
    end
  
    // Reorder columns and return results
    results.reorderCols(["timestamp", "horizon", "quantile", "pred_ts", "pred_val"])
  end
---
name:wattilePythonModelSetup
func
overridable
src:
  (session, model) => do
    // Get local directory uri from model record
    uri: (model.toRec)["uri"]
  
    // Verify uri is a directory, exists, and is not empty
    if (uri.isNull) throw "Model must have a valid 'uri' tag"
    if (not uriIsDir(uri)) throw "Uri `" + uri.toStr + "` is not a directory"
    if (ioDir(uri).isEmpty) throw "Model directory `" + uri.toStr + "` is empty or does not exist"
    
   // Convert absolute to relative Uri
    if (uri.toStr.startsWith("/")) do
      // Verify absolute uri is for the active project
      // Convention is /proj/{projName}/io/...
      modelProj: uriPath(uri)[1]
      
      if (modelProj != context()->projName) do
        throw "Wattile model directory must be in the active project"
      end
      
      // Convert to relative Uri mounted at `io/`
      uri = uriPath(uri)[2..-1].pathToUri.uriPlusSlash
    end
    
    // Load model config in Python
    session
      .pyDefine("model_dir", "/" + uri.toStr)
      .pyExec("configs_path = pathlib.Path(model_dir) / 'configs.json'")
      .pyExec("""with open(configs_path, 'r', encoding='utf-8') as f:
                     configs = json.load(f)""")
    
    // Update configs: model directory, prediction use case
    session
      .pyExec("configs['data_output']['exp_dir'] = model_dir")
      .pyExec("configs['learning_algorithm']['use_case'] = 'prediction'")
    
    // Save configs
    session
      .pyExec("""with open(configs_path, 'w', encoding='utf-8') as f:
                     json.dump(configs, f, indent = 2)""")
    
    // Return "ok" (from Python to verify it all worked)
    session.pyEval("'ok'")
  end